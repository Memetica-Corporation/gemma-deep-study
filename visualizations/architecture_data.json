{
  "model_type": "gemma",
  "vocab_size": 256000,
  "hidden_size": 3072,
  "intermediate_size": 12288,
  "num_hidden_layers": 42,
  "num_attention_heads": 16,
  "num_key_value_heads": 8,
  "max_position_embeddings": 131072,
  "rope_theta": 10000,
  "sliding_window": 1024,
  "total_params": 4000000000,
  "trainable_params": 4000000000,
  "attention_info": {
    "total_attention_layers": 42,
    "local_layers": [
      0,
      1,
      2,
      3,
      4,
      6,
      7,
      8,
      9,
      10,
      12,
      13,
      14,
      15,
      16,
      18,
      19,
      20,
      21,
      22,
      24,
      25,
      26,
      27,
      28,
      30,
      31,
      32,
      33,
      34,
      36,
      37,
      38,
      39,
      40
    ],
    "global_layers": [
      5,
      11,
      17,
      23,
      29,
      35,
      41
    ],
    "attention_heads": 16,
    "kv_heads": 8,
    "head_dim": 192,
    "local_to_global_ratio": 5.0
  },
  "memory_info": {
    "model_size_gb": 8.0,
    "fp32_size_gb": 16.0,
    "int8_size_gb": 4.0,
    "int4_size_gb": 2.0,
    "kv_cache_1024_gb": 0.5,
    "kv_cache_4096_gb": 2.0,
    "kv_cache_16384_gb": 8.0,
    "kv_cache_131072_gb": 64.0,
    "kv_cache_131072_optimized_gb": 12.8
  },
  "layers": [
    {
      "name": "model.embed_tokens",
      "layer_type": "Embedding",
      "params": 786432000,
      "input_shape": [
        1
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {},
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "Token embeddings: Converts input tokens to dense vectors"
    },
    {
      "name": "model.layers.0.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.0.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.0.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.0.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.0.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.0.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.0.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.1.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.1.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.1.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.1.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.1.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.1.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.1.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.2.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.2.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.2.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.2.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.2.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.2.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.2.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.3.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.3.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.3.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.3.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.3.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.3.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.3.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.4.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.4.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.4.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.4.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.4.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.4.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.4.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.5.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention q_proj"
    },
    {
      "name": "model.layers.5.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention k_proj"
    },
    {
      "name": "model.layers.5.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention v_proj"
    },
    {
      "name": "model.layers.5.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention o_proj"
    },
    {
      "name": "model.layers.5.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.5.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.5.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.6.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.6.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.6.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.6.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.6.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.6.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.6.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.7.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.7.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.7.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.7.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.7.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.7.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.7.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.8.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.8.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.8.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.8.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.8.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.8.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.8.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.9.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.9.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.9.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.9.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.9.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.9.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.9.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.10.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.10.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.10.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.10.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.10.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.10.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.10.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.11.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention q_proj"
    },
    {
      "name": "model.layers.11.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention k_proj"
    },
    {
      "name": "model.layers.11.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention v_proj"
    },
    {
      "name": "model.layers.11.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention o_proj"
    },
    {
      "name": "model.layers.11.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.11.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.11.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.12.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.12.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.12.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.12.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.12.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.12.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.12.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.13.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.13.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.13.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.13.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.13.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.13.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.13.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.14.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.14.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.14.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.14.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.14.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.14.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.14.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.15.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.15.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.15.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.15.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.15.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.15.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.15.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.16.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.16.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.16.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.16.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.16.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.16.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.16.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.17.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention q_proj"
    },
    {
      "name": "model.layers.17.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention k_proj"
    },
    {
      "name": "model.layers.17.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention v_proj"
    },
    {
      "name": "model.layers.17.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention o_proj"
    },
    {
      "name": "model.layers.17.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.17.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.17.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.18.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.18.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.18.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.18.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.18.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.18.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.18.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.19.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.19.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.19.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.19.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.19.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.19.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.19.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.20.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.20.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.20.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.20.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.20.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.20.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.20.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.21.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.21.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.21.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.21.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.21.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.21.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.21.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.22.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.22.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.22.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.22.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.22.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.22.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.22.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.23.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention q_proj"
    },
    {
      "name": "model.layers.23.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention k_proj"
    },
    {
      "name": "model.layers.23.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention v_proj"
    },
    {
      "name": "model.layers.23.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention o_proj"
    },
    {
      "name": "model.layers.23.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.23.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.23.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.24.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.24.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.24.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.24.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.24.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.24.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.24.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.25.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.25.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.25.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.25.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.25.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.25.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.25.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.26.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.26.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.26.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.26.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.26.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.26.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.26.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.27.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.27.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.27.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.27.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.27.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.27.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.27.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.28.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.28.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.28.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.28.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.28.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.28.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.28.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.29.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention q_proj"
    },
    {
      "name": "model.layers.29.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention k_proj"
    },
    {
      "name": "model.layers.29.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention v_proj"
    },
    {
      "name": "model.layers.29.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention o_proj"
    },
    {
      "name": "model.layers.29.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.29.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.29.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.30.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.30.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.30.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.30.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.30.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.30.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.30.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.31.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.31.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.31.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.31.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.31.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.31.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.31.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.32.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.32.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.32.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.32.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.32.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.32.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.32.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.33.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.33.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.33.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.33.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.33.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.33.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.33.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.34.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.34.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.34.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.34.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.34.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.34.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.34.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.35.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention q_proj"
    },
    {
      "name": "model.layers.35.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention k_proj"
    },
    {
      "name": "model.layers.35.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention v_proj"
    },
    {
      "name": "model.layers.35.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention o_proj"
    },
    {
      "name": "model.layers.35.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.35.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.35.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.36.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.36.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.36.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.36.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.36.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.36.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.36.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.37.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.37.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.37.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.37.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.37.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.37.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.37.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.38.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.38.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.38.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.38.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.38.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.38.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.38.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.39.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.39.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.39.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.39.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.39.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.39.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.39.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.40.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention q_proj"
    },
    {
      "name": "model.layers.40.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention k_proj"
    },
    {
      "name": "model.layers.40.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention v_proj"
    },
    {
      "name": "model.layers.40.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": true,
      "is_global": false,
      "description": "Local (1024 tokens) attention o_proj"
    },
    {
      "name": "model.layers.40.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.40.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.40.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    },
    {
      "name": "model.layers.41.self_attn.q_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention q_proj"
    },
    {
      "name": "model.layers.41.self_attn.k_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention k_proj"
    },
    {
      "name": "model.layers.41.self_attn.v_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention v_proj"
    },
    {
      "name": "model.layers.41.self_attn.o_proj",
      "layer_type": "Linear",
      "params": 9437184,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 3072
      },
      "is_attention": true,
      "is_local": false,
      "is_global": true,
      "description": "Global attention o_proj"
    },
    {
      "name": "model.layers.41.mlp.gate_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP gate_proj"
    },
    {
      "name": "model.layers.41.mlp.up_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        3072
      ],
      "output_shape": [
        1,
        12288
      ],
      "attributes": {
        "in_features": 3072,
        "out_features": 12288
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP up_proj"
    },
    {
      "name": "model.layers.41.mlp.down_proj",
      "layer_type": "Linear",
      "params": 37748736,
      "input_shape": [
        1,
        12288
      ],
      "output_shape": [
        1,
        3072
      ],
      "attributes": {
        "in_features": 12288,
        "out_features": 3072
      },
      "is_attention": false,
      "is_local": false,
      "is_global": false,
      "description": "MLP down_proj"
    }
  ]
}